{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is taken from the gender identification example at https://www.nltk.org/book/ch06.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first try at Naive Bayes classification using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor\n",
    "We will use one feature from a name: the last letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}\n",
    "gender_features('Stanley')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "Prepare a list of examples with corresponding class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "\n",
    "# display(names.words('male.txt'))\n",
    "\n",
    "male = [(name, 'male') for name in names.words('male.txt')]\n",
    "female = [(name, 'female') for name in names.words('female.txt')]\n",
    "labeled_names = male + female\n",
    "\n",
    "random.shuffle(labeled_names)\n",
    "labeled_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/test data\n",
    "Use the feature extractor to prepare training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "# display(train_set[:3])\n",
    "\n",
    "# Uses multinomial naive Bayes classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out on a few names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "female\n",
      "female\n",
      "female\n",
      "male\n"
     ]
    }
   ],
   "source": [
    "print(classifier.classify(gender_features('Neo')))\n",
    "print(classifier.classify(gender_features('Trinity')))\n",
    "print(classifier.classify(gender_features('Amy')))\n",
    "print(classifier.classify(gender_features('Andy')))\n",
    "print(classifier.classify(gender_features('Laren')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood ratios\n",
    "Names in the training set that end in \"a\" are female 34 times more often than they are male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we do better?\n",
    "Update the feature extractor to see if we can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.scores import (precision, recall)\n",
    "\n",
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features\n",
    "\n",
    "gender_features('Hephzibah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "female\n",
      "female\n",
      "female\n",
      "0.77\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     37.3 : 1.0\n",
      "             last_letter = 'k'              male : female =     32.6 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.9 : 1.0\n",
      "             last_letter = 'p'              male : female =     12.5 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(classifier.classify(gender_features('Neo')))\n",
    "print(classifier.classify(gender_features('Trinity')))\n",
    "print(classifier.classify(gender_features('Amy')))\n",
    "print(classifier.classify(gender_features('Andy')))\n",
    "\n",
    "\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "# classifier.classify_many(test_set)\n",
    "# print('Precision: {}'.format(precision(refsets['pos'], testsets['pos'])))\n",
    "# print 'Recall:', nltk.metrics.recall(refsets['pos'], testsets['pos'])\n",
    "\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do it with scipy-learn\n",
    "Adapted from https://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.84615385 1.        ] [1.         1.         0.85714286]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Use Gaussian for general datasets\n",
    "clf = GaussianNB()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "p,r,f,s = precision_recall_fscore_support(y_test, y_pred)\n",
    "print(p, r) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81619938 0.70391061] [0.83174603 0.68108108] [0.82389937 0.69230769]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy\n",
    "import numpy as np\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([l for l in alphabet])\n",
    "\n",
    "def gender_features(name):\n",
    "    features = []\n",
    "    first = name[0].lower()\n",
    "    last = name[-1].lower()\n",
    "\n",
    "    a = np.zeros(len(alphabet))\n",
    "    a[le.transform([first])[0]] = 1\n",
    "    features.extend(a)\n",
    "\n",
    "    a = np.zeros(len(alphabet))\n",
    "    if alphabet.find(last) > -1:\n",
    "        a[le.transform([last])[0]] = 1\n",
    "    features.extend(a)\n",
    "\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features.append(name.lower().count(letter))\n",
    "        features.append(letter in name.lower())\n",
    "    return features\n",
    "\n",
    "\n",
    "# display(gender_features(\"Hank\"))\n",
    "\n",
    "random.shuffle(labeled_names)\n",
    "X = [gender_features(name) for (name, _) in labeled_names]\n",
    "y = [gender for (_, gender) in labeled_names]\n",
    "X\n",
    "\n",
    "X_train, X_test = X[500:], X[:500]\n",
    "y_train, y_test = y[500:], y[:500]\n",
    "\n",
    "# Use multinomial for text classification\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train).predict(X_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "p,r,f,s = precision_recall_fscore_support(y_test, y_pred)\n",
    "print(p, r, f)                                                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
