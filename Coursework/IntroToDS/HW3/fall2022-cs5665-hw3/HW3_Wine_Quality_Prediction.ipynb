{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mz0_QVkxCrX3"
   },
   "source": [
    "# **Homework 3: Wine Quality Prediction (Classification)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SxwRwMfVlIrN"
   },
   "outputs": [],
   "source": [
    "Name = \"Ben Shaw\"\n",
    "assert Name != \"\", 'Please enter your name in the above quotation marks, thanks!'\n",
    "\n",
    "A_number = \"A01515327\"\n",
    "assert A_number != \"\", 'Please enter your A-number in the above quotation marks, thanks!'\n",
    "\n",
    "Kaggle_username=\"Ben D Shaw\"\n",
    "assert Kaggle_username != \"\", 'Please enter your Kaggle username in the above quotation marks, thanks!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeZnPAiwDRWG"
   },
   "source": [
    "\n",
    "In this homework, we aim to predict the wine quality by a neural network. In this sample code, we implement a barely work neural network, and your job is to implement the performance. You can find the meta data of this dataset [here](https://archive.ics.uci.edu/ml/datasets/wine). Please download the dataset either from [Kaggle](https://www.kaggle.com/t/957a7547ea0745b191ac74652c38211b) or Canvas and DO NOT use the original dataset as we slightly revise the data.\n",
    "\n",
    "Your jobs:\n",
    "\n",
    "1. Run sample code.\n",
    "\n",
    "2. **Make substantial improvements** to improve the accuracy.\n",
    "\n",
    "3. Submit the .IPYNB file to Canvas.\n",
    "    - Missing the output after execution may hurt your grade.\n",
    "\n",
    "4. Submit the generated \"pred.csv\" to the [inclass Kaggle competition](https://www.kaggle.com/t/957a7547ea0745b191ac74652c38211b). Your score will be based on the accuracy on the private dataset. Please check [Canvas](https://usu.instructure.com/courses/706364/assignments/3897628) for details.\n",
    "\n",
    "# **Hints**\n",
    "* Feature engineering (all features  or less features)\n",
    "* Feature normalization or standardization\n",
    "* DNN architecture (layers? dimension? activation function?)\n",
    "* Training (mini-batch? optimizer? learning rate?)\n",
    "* L1/L2 regularization\n",
    "\n",
    "# **Rules**\n",
    "\n",
    "- You should finish your homework on your own.\n",
    "- **You should not modify your prediction files manually.**\n",
    "- Do not share codes or prediction files with any living creatures.\n",
    "- **Do not search or use additional data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfrVxqJanGpE"
   },
   "source": [
    "**Please describe your improvements here**\n",
    "\n",
    "- One: Change in the number of layers: added two layers\n",
    "- Two: Added L2 regularization\n",
    "- Three: changed to Adam optimizer\n",
    "- Four: implemented PCA (9 components) during preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4Ag_jkzqSzW"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jx3x1nDkG-Uy"
   },
   "source": [
    "# **Download Data**\n",
    "\n",
    "\n",
    "You can download data from [kaggle](https://www.kaggle.com/t/957a7547ea0745b191ac74652c38211b). If you use Google Colab, you should upload the data files to the same workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tMj55YDKG6ch"
   },
   "outputs": [],
   "source": [
    "train_path = './wine_train.csv'  # path to training data\n",
    "test_path = './wine_test.csv'   # path to testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS_4-77xHk44"
   },
   "source": [
    "# **Import Some Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "k-onQd4JNA5H"
   },
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For data preprocess\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "myseed = 42  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtE3b6JEH7rw"
   },
   "source": [
    "# **Some Utilities**\n",
    "\n",
    "You do not need to modify this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FWMT3uf1NGQp"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    ''' Get device (if GPU is available, use GPU) '''\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def plot_learning_curve(loss_record, title=''):\n",
    "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
    "    total_steps = len(loss_record['train'])\n",
    "    x_1 = range(total_steps)\n",
    "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
    "    figure(figsize=(6, 4))\n",
    "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
    "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
    "    plt.ylim(0.0, 5.)\n",
    "    plt.xlabel('Training steps')\n",
    "    plt.ylabel('Cross entropy loss')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39U_XFX6KOoj"
   },
   "source": [
    "# **Preprocess**\n",
    "\n",
    "We have three kinds of datasets:\n",
    "* `train`: for training\n",
    "* `dev`: for validation\n",
    "* `test`: for testing (w/o target value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQ-MdwpLL7Dt"
   },
   "source": [
    "## **Dataset**\n",
    "\n",
    "The `WineDataset` below does:\n",
    "* read `.csv` files\n",
    "* extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0zlpIp9ANJRU"
   },
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    ''' Dataset for loading and preprocessing the Wine dataset '''\n",
    "\n",
    "    def __init__(self, path, mode='train', target_only=False):\n",
    "        self.mode = mode\n",
    "\n",
    "        # Read data into numpy arrays\n",
    "        with open(path, 'r') as fp:\n",
    "            data = list(csv.reader(fp))\n",
    "            data = np.array(data[1:]).astype(float)\n",
    "\n",
    "        if not target_only:\n",
    "            feats = list(range(11))\n",
    "        else:\n",
    "            # TODO: Using other features\n",
    "            feats = list(range(11)) #[1,2,3,4,5,6,7,8,10]\n",
    "            \n",
    "            #Now normalize the features?\n",
    "            \n",
    "            pass\n",
    "\n",
    "        if mode == 'test':\n",
    "            # Testing data\n",
    "            data = data[:, feats]\n",
    "            data = pca.fit_transform(data)       #could using PCA help?\n",
    "            self.data = torch.FloatTensor(data)\n",
    "        else:\n",
    "            # Training data (train/dev sets)\n",
    "            target = data[:, -1]\n",
    "            data = data[:, feats]\n",
    "            data = pca.fit_transform(data)                     #Could using PCA help?\n",
    "            #Normalize\n",
    "            #data = preprocessing.normalize(data, axis=0)\n",
    "\n",
    "            # Splitting training data into train & dev sets\n",
    "            if mode == 'train':\n",
    "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
    "            elif mode == 'dev':\n",
    "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
    "\n",
    "            # Convert data into PyTorch tensors\n",
    "            self.data = torch.FloatTensor(data[indices])\n",
    "            self.target = torch.FloatTensor(target[indices])\n",
    "\n",
    "        self.dim = self.data.shape[1]\n",
    "\n",
    "        print('Finished reading the {} set of Wine Dataset ({} samples found, each dim = {})'.format(mode, len(self.data), self.dim))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample at a time\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            # For training\n",
    "            return self.data[index], self.target[index]\n",
    "        else:\n",
    "            # For testing (no target)\n",
    "            return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the size of the dataset\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlhTlkE7MDo3"
   },
   "source": [
    "## **DataLoader**\n",
    "\n",
    "A `DataLoader` loads data from a given `Dataset` into batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hlhLk5t6MBX3"
   },
   "outputs": [],
   "source": [
    "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
    "    ''' Generates a dataset, then is put into a dataloader. '''\n",
    "    dataset = WineDataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=(mode == 'train'), drop_last=False,num_workers=n_jobs, pin_memory=True)  # Construct dataloader                          \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGuycwR0MeQB"
   },
   "source": [
    "# **Deep Neural Network**\n",
    "\n",
    "`NeuralNet` is an `nn.Module` designed for calssification.\n",
    "The DNN consists of 2 fully-connected layers with ReLU activation.\n",
    "This module also included a function `cal_loss` for calculating loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "49-uXYovOAI0"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    ''' A simple fully-connected deep neural network '''\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # Define your neural network here\n",
    "        # TODO: How to modify this model to achieve better performance?\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 3200),\n",
    "            #nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(3200,800),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(800,200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 3),\n",
    "            #nn.ReLU()\n",
    "            #nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        # Cross entropy loss\n",
    "        self.criterion =  nn.CrossEntropyLoss() #nn.NLLLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        ''' Calculate loss '''\n",
    "        # TODO: you may implement L1/L2 regularization here\n",
    "        \n",
    "        #Replace pow(2.0) with abs() for L1 regularization\n",
    "     \n",
    "        l2_lambda = 0.001 #0.001\n",
    "        l2_norm = sum(p.pow(2.0).sum()\n",
    "                  for p in model.parameters())\n",
    " \n",
    "        lossL2 = l2_lambda * l2_norm\n",
    "        return self.criterion(pred, target) + lossL2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvFWVjZ5Nvga"
   },
   "source": [
    "# **Train/Dev/Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAM8QecJOyqn"
   },
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lOqcmYzMO7jB"
   },
   "outputs": [],
   "source": [
    "def train(tr_set, dv_set, model, config, device):\n",
    "    ''' DNN training '''\n",
    "\n",
    "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
    "\n",
    "    # Setup optimizer\n",
    "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
    "        model.parameters(), **config['optim_hparas'])\n",
    "\n",
    "    min_ce = 1000.\n",
    "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
    "    early_stop_cnt = 0\n",
    "    epoch = 0\n",
    "    while epoch < n_epochs:\n",
    "        model.train()                           # set model to training mode\n",
    "        for x, y in tr_set:                     # iterate through the dataloader\n",
    "            optimizer.zero_grad()               # set gradient to zero\n",
    "            x, y = x.to(device), y.long().to(device)   # move data to device (cpu/cuda)\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            crossentropy_loss = model.cal_loss(pred, y)  # compute loss\n",
    "            crossentropy_loss.backward()                 # compute gradient (backpropagation)\n",
    "            optimizer.step()                    # update model with optimizer\n",
    "            loss_record['train'].append(crossentropy_loss.detach().cpu().item())\n",
    "\n",
    "        # After each epoch, test your model on the validation (development) set.\n",
    "        dev_ce= dev(dv_set, model, device)[0]\n",
    "        if dev_ce < min_ce:\n",
    "            # Save model if your model improved\n",
    "            min_ce = dev_ce\n",
    "            print('Saving model (epoch = {:4d}, loss = {:.4f})'.format(epoch + 1, min_ce))\n",
    "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "\n",
    "        epoch += 1\n",
    "        loss_record['dev'].append(dev_ce)\n",
    "        if early_stop_cnt > config['early_stop']:\n",
    "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
    "            break\n",
    "\n",
    "    print('Finished training after {} epochs'.format(epoch))\n",
    "    return min_ce, loss_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hSd4Bn3O2PL"
   },
   "source": [
    "## **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yrxrD3YsN3U2"
   },
   "outputs": [],
   "source": [
    "def dev(dv_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    preds = []\n",
    "    total_loss = 0\n",
    "    for x, y in dv_set:                         # iterate through the dataloader\n",
    "        x, y = x.to(device), y.long().to(device)       # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            preds.append(pred.detach().cpu())\n",
    "            ce_loss = model.cal_loss(pred, y)  # compute loss\n",
    "        total_loss += ce_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
    "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "\n",
    "    return total_loss, np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0pdrhQAO41L"
   },
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aSBMRFlYN5tB"
   },
   "outputs": [],
   "source": [
    "def test(tt_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    preds = []\n",
    "    for x in tt_set:                            # iterate through the dataloader\n",
    "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            preds.append(pred.detach().cpu())   # collect prediction\n",
    "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvckkF5dvf0j"
   },
   "source": [
    "# **Setup Hyper-parameters**\n",
    "\n",
    "`config` contains hyper-parameters for training and the path to save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NPXpdumwPjE7"
   },
   "outputs": [],
   "source": [
    "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
    "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
    "target_only = True #False                   # TODO: select features\n",
    "\n",
    "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
    "config = {\n",
    "    'n_epochs': 1000,                # maximum number of epochs\n",
    "    'batch_size': 128,               # mini-batch size for dataloader\n",
    "    'optimizer': 'Adam',              # optimization algorithm (optimizer in torch.optim)\n",
    "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
    "        'lr': 0.0001,                 # learning rate of SGD\n",
    "        #'momentum': 0.9              # momentum for SGD\n",
    "    },\n",
    "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
    "    'save_path': 'models/model.pth'  # your model will be saved here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j1eOV3TOH-j"
   },
   "source": [
    "# **Load data and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNrYBMmePLKm",
    "outputId": "ddda1ef8-9cc1-4cc2-bc20-c4db0cae41a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the train set of Wine Dataset (2700 samples found, each dim = 9)\n",
      "Finished reading the dev set of Wine Dataset (300 samples found, each dim = 9)\n",
      "Finished reading the test set of Wine Dataset (1500 samples found, each dim = 9)\n"
     ]
    }
   ],
   "source": [
    "tr_set = prep_dataloader(train_path, 'train', config['batch_size'], target_only=target_only)\n",
    "dv_set = prep_dataloader(train_path, 'dev', config['batch_size'], target_only=target_only)\n",
    "tt_set = prep_dataloader(test_path, 'test', config['batch_size'], target_only=target_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FHylSirLP9oh"
   },
   "outputs": [],
   "source": [
    "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sX2B_zgSOPTJ"
   },
   "source": [
    "# **Start Training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GrEbUxazQAAZ",
    "outputId": "5c7faf57-ef39-4ac0-b3a6-701e06d3d730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model (epoch =    1, loss = 2.4998)\n",
      "Saving model (epoch =    2, loss = 2.4398)\n",
      "Saving model (epoch =    3, loss = 2.4153)\n",
      "Saving model (epoch =    4, loss = 2.3615)\n",
      "Saving model (epoch =    5, loss = 2.3448)\n",
      "Saving model (epoch =    6, loss = 2.3310)\n",
      "Saving model (epoch =    7, loss = 2.3048)\n",
      "Saving model (epoch =    9, loss = 2.2847)\n",
      "Saving model (epoch =   10, loss = 2.2454)\n",
      "Saving model (epoch =   11, loss = 2.1979)\n",
      "Saving model (epoch =   12, loss = 2.1779)\n",
      "Saving model (epoch =   15, loss = 2.1399)\n",
      "Saving model (epoch =   16, loss = 2.0875)\n",
      "Saving model (epoch =   17, loss = 2.0789)\n",
      "Saving model (epoch =   18, loss = 2.0639)\n",
      "Saving model (epoch =   19, loss = 2.0403)\n",
      "Saving model (epoch =   21, loss = 2.0288)\n",
      "Saving model (epoch =   22, loss = 2.0105)\n",
      "Saving model (epoch =   23, loss = 1.9667)\n",
      "Saving model (epoch =   26, loss = 1.9527)\n",
      "Saving model (epoch =   27, loss = 1.9128)\n",
      "Saving model (epoch =   28, loss = 1.9028)\n",
      "Saving model (epoch =   29, loss = 1.8787)\n",
      "Saving model (epoch =   31, loss = 1.8439)\n",
      "Saving model (epoch =   32, loss = 1.8369)\n",
      "Saving model (epoch =   33, loss = 1.8290)\n",
      "Saving model (epoch =   36, loss = 1.7980)\n",
      "Saving model (epoch =   37, loss = 1.7696)\n",
      "Saving model (epoch =   41, loss = 1.7607)\n",
      "Saving model (epoch =   42, loss = 1.7405)\n",
      "Saving model (epoch =   43, loss = 1.6996)\n",
      "Saving model (epoch =   44, loss = 1.6963)\n",
      "Saving model (epoch =   45, loss = 1.6826)\n",
      "Saving model (epoch =   46, loss = 1.6661)\n",
      "Saving model (epoch =   47, loss = 1.6550)\n",
      "Saving model (epoch =   50, loss = 1.6190)\n",
      "Saving model (epoch =   52, loss = 1.5990)\n",
      "Saving model (epoch =   53, loss = 1.5936)\n",
      "Saving model (epoch =   54, loss = 1.5874)\n",
      "Saving model (epoch =   55, loss = 1.5824)\n",
      "Saving model (epoch =   56, loss = 1.5646)\n",
      "Saving model (epoch =   58, loss = 1.5610)\n",
      "Saving model (epoch =   59, loss = 1.5494)\n",
      "Saving model (epoch =   60, loss = 1.5431)\n",
      "Saving model (epoch =   61, loss = 1.5192)\n",
      "Saving model (epoch =   63, loss = 1.5185)\n",
      "Saving model (epoch =   64, loss = 1.5165)\n",
      "Saving model (epoch =   65, loss = 1.5004)\n",
      "Saving model (epoch =   66, loss = 1.4812)\n",
      "Saving model (epoch =   68, loss = 1.4754)\n",
      "Saving model (epoch =   69, loss = 1.4565)\n",
      "Saving model (epoch =   70, loss = 1.4512)\n",
      "Saving model (epoch =   72, loss = 1.4498)\n",
      "Saving model (epoch =   73, loss = 1.4217)\n",
      "Saving model (epoch =   78, loss = 1.4038)\n",
      "Saving model (epoch =   79, loss = 1.3865)\n",
      "Saving model (epoch =   81, loss = 1.3764)\n",
      "Saving model (epoch =   85, loss = 1.3572)\n",
      "Saving model (epoch =   87, loss = 1.3422)\n",
      "Saving model (epoch =   90, loss = 1.3359)\n",
      "Saving model (epoch =   91, loss = 1.3245)\n",
      "Saving model (epoch =   93, loss = 1.3103)\n",
      "Saving model (epoch =   94, loss = 1.3032)\n",
      "Saving model (epoch =  100, loss = 1.2970)\n",
      "Saving model (epoch =  101, loss = 1.2807)\n",
      "Saving model (epoch =  102, loss = 1.2751)\n",
      "Saving model (epoch =  103, loss = 1.2710)\n",
      "Saving model (epoch =  104, loss = 1.2529)\n",
      "Saving model (epoch =  110, loss = 1.2430)\n",
      "Saving model (epoch =  111, loss = 1.2390)\n",
      "Saving model (epoch =  112, loss = 1.2266)\n",
      "Saving model (epoch =  113, loss = 1.2205)\n",
      "Saving model (epoch =  118, loss = 1.2169)\n",
      "Saving model (epoch =  120, loss = 1.2126)\n",
      "Saving model (epoch =  121, loss = 1.2044)\n",
      "Saving model (epoch =  122, loss = 1.2035)\n",
      "Saving model (epoch =  124, loss = 1.1925)\n",
      "Saving model (epoch =  127, loss = 1.1857)\n",
      "Saving model (epoch =  132, loss = 1.1832)\n",
      "Saving model (epoch =  133, loss = 1.1769)\n",
      "Saving model (epoch =  134, loss = 1.1750)\n",
      "Saving model (epoch =  135, loss = 1.1590)\n",
      "Saving model (epoch =  139, loss = 1.1565)\n",
      "Saving model (epoch =  144, loss = 1.1536)\n",
      "Saving model (epoch =  145, loss = 1.1495)\n",
      "Saving model (epoch =  147, loss = 1.1414)\n",
      "Saving model (epoch =  150, loss = 1.1339)\n",
      "Saving model (epoch =  152, loss = 1.1256)\n",
      "Saving model (epoch =  155, loss = 1.1250)\n",
      "Saving model (epoch =  157, loss = 1.1218)\n",
      "Saving model (epoch =  158, loss = 1.1172)\n",
      "Saving model (epoch =  166, loss = 1.1061)\n",
      "Saving model (epoch =  169, loss = 1.0996)\n",
      "Saving model (epoch =  176, loss = 1.0944)\n",
      "Saving model (epoch =  179, loss = 1.0881)\n",
      "Saving model (epoch =  190, loss = 1.0727)\n",
      "Saving model (epoch =  196, loss = 1.0709)\n",
      "Saving model (epoch =  202, loss = 1.0655)\n",
      "Saving model (epoch =  210, loss = 1.0597)\n",
      "Saving model (epoch =  225, loss = 1.0585)\n",
      "Saving model (epoch =  227, loss = 1.0579)\n",
      "Saving model (epoch =  231, loss = 1.0568)\n",
      "Saving model (epoch =  233, loss = 1.0504)\n",
      "Saving model (epoch =  234, loss = 1.0496)\n",
      "Saving model (epoch =  241, loss = 1.0466)\n",
      "Saving model (epoch =  242, loss = 1.0441)\n",
      "Saving model (epoch =  247, loss = 1.0428)\n",
      "Saving model (epoch =  248, loss = 1.0405)\n",
      "Saving model (epoch =  254, loss = 1.0383)\n",
      "Saving model (epoch =  256, loss = 1.0351)\n",
      "Saving model (epoch =  262, loss = 1.0273)\n",
      "Saving model (epoch =  291, loss = 1.0193)\n",
      "Saving model (epoch =  306, loss = 1.0117)\n",
      "Saving model (epoch =  320, loss = 1.0112)\n",
      "Saving model (epoch =  333, loss = 1.0092)\n",
      "Saving model (epoch =  350, loss = 1.0036)\n",
      "Saving model (epoch =  380, loss = 1.0032)\n",
      "Saving model (epoch =  383, loss = 0.9991)\n",
      "Saving model (epoch =  387, loss = 0.9967)\n",
      "Saving model (epoch =  409, loss = 0.9949)\n",
      "Saving model (epoch =  419, loss = 0.9930)\n",
      "Saving model (epoch =  432, loss = 0.9926)\n",
      "Saving model (epoch =  447, loss = 0.9914)\n",
      "Saving model (epoch =  452, loss = 0.9876)\n",
      "Saving model (epoch =  516, loss = 0.9827)\n",
      "Saving model (epoch =  576, loss = 0.9794)\n",
      "Finished training after 777 epochs\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "hsNO9nnXQBvP",
    "outputId": "222b3112-3709-493b-b64e-531990eb5a82"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nn.BatchNorm2d(num_features=16),\n",
    "plot_learning_curve(model_loss_record, title='deep model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3iZTVn5WQFpX",
    "outputId": "d698c545-51b3-4b52-832d-72185d73d020"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
    "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQikz3IPiyPf"
   },
   "source": [
    "# **Testing**\n",
    "The predictions of your model on testing set will be stored at `pred.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "preds2 = dev(dv_set, model, device)  # predict the quality of wine cases with your model\n",
    "#preds2 = np.argmax(preds, axis=1)\n",
    "preds3 = []\n",
    "for x, y in dv_set:                         # iterate through the dataloader\n",
    "        x, y = x.to(device), y.long().to(device)       # move data to device (cpu/cuda)\n",
    "        #print(y)\n",
    "        ylist = [t.item() for t in y]\n",
    "        preds3.extend(ylist)\n",
    "        \n",
    "rights = [1 for i in range(len(preds3)) if preds2[1][i]==preds3[i]]\n",
    "print(len(rights)/len(preds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8cTuQjQQOon",
    "outputId": "5220e7e2-fdad-49e0-f75a-a6544ce79a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to pred.csv\n"
     ]
    }
   ],
   "source": [
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    print('Saving results to {}'.format(file))\n",
    "    with open(file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])\n",
    "\n",
    "preds = test(tt_set, model, device)  # predict the quality of wine cases with your model\n",
    "preds = np.argmax(preds, axis=1) # trasfer output to predicted labels\n",
    "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uuRfprxlIrV"
   },
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`.\n",
    "2. Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Please keep your notebook clean and remove any throwaway code.\n",
    "4. **Please upload the pred.csv to the [class competition](https://www.kaggle.com/t/957a7547ea0745b191ac74652c38211b).** The score of this homework is based on the result on the private datset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tmCwXgpot3t"
   },
   "source": [
    "# **Reference**\n",
    "This code is adapted from Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb).  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
