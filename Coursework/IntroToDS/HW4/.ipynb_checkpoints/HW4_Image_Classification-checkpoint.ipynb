{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e63rmXOtVyys",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 4: Image Classification\n",
    "\n",
    "**Name:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fB_Wp-tBUyFn",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Name = \"Ben Shaw\"\n",
    "assert Name != \"\", 'Please enter your name, thanks!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oxtoxlQYJWe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**A-Number:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTPPvA-CYPVo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "A_number = \"A01515327\"\n",
    "assert A_number != \"\", 'Please enter your A-number, thanks!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YST4g_loYMU8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Kaggle-UserName:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZjny9zCYSE3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Kaggle_UserName = \"Ben D Shaw\"\n",
    "assert Kaggle_UserName != \"\", 'Please enter your Kaggle Username, thanks!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0J-3RX7amNe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this homework, we will train a CNN model on EuroSAT. EuroSAT is a dataset consisting of images of the Earth provided by the Sentinel-2 satellite. The dataset contains ten types of images, so it is a dataset for multiclass classification. You can find more information about EuroSAT [here](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8736785).\n",
    "\n",
    " **Please download the dataset from the [inclass Kaggle competition](https://www.kaggle.com/t/9642f138df72494ea456f05b0a70a4b0) as we split the original dataset into the train-valid-test sets.**\n",
    "\n",
    "This notebook contains a baseline model to train on EuroSAT. Please use it as a starting point. **The purpose of this homework is to design an advanced CNN model to achieve better performance on EuroSAT by yourself. You are not allowed to import pre-trained models. In case you are interested, we provide a sample code by using a pre-trained model, Resnet50.** \n",
    "\n",
    "Your jobs \n",
    "\n",
    "1.   Read, complete, and run the code.\n",
    "\n",
    "2.   **Make substantial improvements** to maximize the accurcy.\n",
    "\n",
    "3.   Submit the .IPYNB file to Canvas.\n",
    "    - Missing the output after execution may hurt your grade.\n",
    "\n",
    "4.   Submit the generated \"pred.csv\" to the [inclass Kaggle competition](https://www.kaggle.com/t/9642f138df72494ea456f05b0a70a4b0).\n",
    "\n",
    "\n",
    "# **Rules**\n",
    "\n",
    "- You should finish your homework on your own.\n",
    "- **You should not modify your prediction files manually.**\n",
    "- Do not share codes or prediction files with any living creatures.\n",
    "- **Do not search or use additional data.**\n",
    "- **Do not use any pre-trained models.**\n",
    "\n",
    "\n",
    "## Hints to Improve Your Results\n",
    "\n",
    "* You'd better use a GPU machine to run it, otherwise it'll be quite slow.\n",
    "* Revise the simple CNN model\n",
    "* Revise the *transforms* function by using some image augumentation techniques\n",
    "* Tune hyper-parameters, such as batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJnaovZBamNe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Please describe your improvements here**:\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCSzGfAzamNf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, import the packages or modules required for the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nscdzE4amNf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "device = 'cuda'\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIiU4S37amNf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fX6BfOitbp2C"
   },
   "source": [
    "### Download the dataset to Colab from Kaggle. \n",
    "\n",
    "**You need to have your Kaggle Token at hand**. Please find [this article](https://medium.com/@opalkabert/downloading-kaggle-datasets-into-google-colab-fb9654c94235) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIkqENNCoPUz"
   },
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "# I added this if statement to make it easier to run all cells without having to re-upload the kaggle.json file\n",
    "if not exists(\"kaggle.json\"):\n",
    "  from google.colab import files\n",
    "  files.upload()   ## Upload your Kaggle token file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "J7xscESTb1D0",
    "outputId": "20aedd58-9497-4be6-bc79-efa9ca8a1f26"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!kaggle competitions download -c fall2022-cs5665-hw4   ## You need to join the competition first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2j4sZB9cMl0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "local_zip = 'fall2022-cs5665-hw4.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ke521j5amNf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading and normalizing \n",
    "\n",
    "Using torchvision, itâ€™s extremely easy to load EuroSAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QsWjoemkamNk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# train images: 18900, val images: 2700, test images: 5400\n",
    "trainset = torchvision.datasets.ImageFolder(root='./Dataset/train', transform=transform)\n",
    "valset = torchvision.datasets.ImageFolder(root='./Dataset/val', transform=transform)\n",
    "testset = torchvision.datasets.ImageFolder(root='./Dataset/test', transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('Forest', 'AnnualCrop', 'Industrial', 'Residential', 'Pasture', \n",
    "           'River', 'PermanentCrop', 'SeaLake', 'Highway', 'HerbaceousVegetation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "C_zWrJAdamNk",
    "outputId": "6554ff06-936b-4bb3-b6c5-52b3f1fcdfb3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7Fv3o2JamNl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmPrkYEyamNl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 13 * 13, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 13 * 13)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCbQuDPgamNl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKNP657PamNm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define the Training Functions\n",
    "\n",
    "We will select the model and tune hyper-parameters according to the model's performance on the validation set. Next, we define the model training function `train`. We record the training time of each epoch, which helps us compare the time costs of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "0b5Rx5fTamNm",
    "outputId": "a2d763a1-9e5a-4129-deb6-37ac967228ad",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "best_val_acc = -1000\n",
    "best_val_model = None\n",
    "acc_record = {'train': [], 'dev': []} # added\n",
    "for epoch in range(20):  \n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(),labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        out = torch.argmax(outputs.detach(),dim=1)\n",
    "        assert out.shape==labels.shape\n",
    "        running_acc += (labels==out).sum().item()\n",
    "    acc_record['train'].append(running_acc/len(trainset))  # added\n",
    "    print(f\"Train loss {epoch+1}: {running_loss/len(trainset)},Train Acc:{running_acc*100/len(trainset)}%\")\n",
    "    \n",
    "    correct = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in valloader:\n",
    "            out = net(inputs.cuda()).cpu()\n",
    "            out = torch.argmax(out,dim=1)\n",
    "            acc = (out==labels).sum().item()\n",
    "            correct += acc\n",
    "    acc_record['dev'].append(correct/len(valset))  # added\n",
    "    print(f\"Val accuracy:{correct*100/len(valset)}%\")\n",
    "    if correct>best_val_acc:\n",
    "        best_val_acc = correct\n",
    "        best_val_model = deepcopy(net.state_dict())\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "print('Finished Training')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7A_66Xx3K8Z"
   },
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Learning curve\n",
    "I just modified the learning curve function from Homework 3. You're more than welcome to change anything you dislike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pzqcal9I1qWU"
   },
   "outputs": [],
   "source": [
    "# This is mo\n",
    "def plot_learning_curve(acc_record, title=''):\n",
    "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
    "    x_1 = range(len(acc_record['train']))\n",
    "    x_2 = range(len(acc_record['dev']))\n",
    "    figure(figsize=(6, 4))\n",
    "    plt.plot(x_1, acc_record['train'], c='tab:red', label='train')\n",
    "    plt.plot(x_2, acc_record['dev'], c='tab:cyan', label='dev')\n",
    "    y_min = min(min(acc_record['train']), min(acc_record['dev']))\n",
    "    y_max = max(max(acc_record['train']), max(acc_record['dev']))\n",
    "\n",
    "    # TODO: feel free to change this range to see the learning curve better\n",
    "    plt.ylim(max(.95*y_min-0.01, 0.5), min(1.05*y_max+0.01, 1))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "hEnsZydy1rPh",
    "outputId": "8c2280bd-7b19-4e94-a04b-dc91800d2802"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(acc_record, title='deep model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "v6fzf0qNOqV9",
    "outputId": "7b6b849c-d107-4003-da5e-9fbf82f01ac1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = []\n",
    "net.load_state_dict(best_val_model)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs,labels in testloader:\n",
    "        out = net(inputs.cuda()).cpu()\n",
    "        out = torch.argmax(out,dim=1)\n",
    "        preds.append(out.detach().cpu())\n",
    "preds = torch.cat(preds, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UikJsCXAP9J5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('pred.csv', 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'label'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gewjHPJCamNn"
   },
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`.\n",
    "2. Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Please keep your notebook clean and remove any throwaway code.\n",
    "4. **Please upload the pred.csv to the [class competition](https://www.kaggle.com/competitions/fall2022-cs5665-hw4/overview).** The score of this homework is based on the result on the private datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxC7ef47amNn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "abc8709615b5f81fced745e59133b05a7ce14864da8ef4169d80ff831846d0e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
